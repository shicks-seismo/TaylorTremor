{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d859851-f8e5-4b6b-bb6f-83f89df0bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read_inventory\n",
    "import pandas as pd\n",
    "from obspy.clients.filesystem.sds import Client\n",
    "from obspy import UTCDateTime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.signal.filter import envelope\n",
    "import matplotlib.mlab as mlab\n",
    "from obspy.signal.util import next_pow_2\n",
    "from datetime import timedelta, datetime\n",
    "import matplotlib.dates as mdates\n",
    "from obspy import Stream\n",
    "from numpy import trapz\n",
    "from scipy.integrate import simpson\n",
    "from matplotlib.dates import DateFormatter\n",
    "import pandas as pd\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib\n",
    "font_dir = ['/Users/sph1r17/Downloads/Source_Sans_Pro']\n",
    "for font in font_manager.findSystemFonts(font_dir):\n",
    "    font_manager.fontManager.addfont(font)\n",
    "matplotlib.rc('font', family='Source Sans Pro') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76e723-0442-4bbe-8fb9-c49f72f994ad",
   "metadata": {},
   "source": [
    "# 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467e4f9-4872-4101-8c5d-c5e94f1cf628",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(\"/Volumes/WembleyData/\")\n",
    "\n",
    "ot_fri = UTCDateTime(\"2024-06-21T18:24:00.000Z\")\n",
    "ot_sat = UTCDateTime(\"2024-06-22T18:20:00.000Z\")\n",
    "ot_sun = UTCDateTime(\"2024-06-23T17:29:00.000Z\")\n",
    "\n",
    "st_fri = c.get_waveforms(network=\"TS\", station=\"WEM05\", location=\"00\", channel=\"CH*\",\n",
    "                         starttime=ot_fri-(1.5*60*60), endtime=ot_fri+(4.5*60*60))\n",
    "\n",
    "for n_tr, tr in enumerate(st_fri):\n",
    "    st_fri[n_tr].stats.starttime = tr.stats.starttime + 3600   # Add on one hour for UTC->BST time\n",
    "\n",
    "st_fri_ = st_fri.copy()\n",
    "st_fri_.decimate(10)\n",
    "st_fri_.remove_response(inventory=inv, output=\"DISP\")\n",
    "st_fri_.detrend(type=\"demean\")\n",
    "st_fri_.detrend(type=\"linear\")\n",
    "st_fri_.filter(\"bandpass\", freqmin=2, freqmax=8)\n",
    "st_fri_.taper(max_percentage=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c192f5f-186a-4164-b865-589e0e839f43",
   "metadata": {},
   "source": [
    "# 2. Read in set list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca96af-696d-45f4-b4cb-1d0159f2ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/sph1r17/Downloads/songs_times_25_June.dat\")\n",
    "df[\"Song name\"] = df[\"Song name\"].str.strip()\n",
    "df[\"Starttime\"] = pd.to_datetime(df[\"Starttime\"])\n",
    "df[\"Endtime\"] = pd.to_datetime(df[\"Endtime\"])\n",
    "\n",
    "fig, axs = plt.subplots(7, 7, figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for idx, r in df.iterrows():\n",
    "    st_fri_trim = st_fri_.slice(UTCDateTime(r[\"Starttime\"]), UTCDateTime(r[\"Endtime\"]))\n",
    "    st_vert = st_fri_trim.select(component=\"Z\")\n",
    "    st_horiz = st_fri_trim.copy()\n",
    "    tr_E = st_fri_trim.select(component=\"E\")[0]\n",
    "    tr_N = st_fri_trim.select(component=\"N\")[0]\n",
    "\n",
    "\n",
    "    for tr in st_horiz:\n",
    "        if tr.stats.component==\"Z\":\n",
    "            st_horiz.remove(tr)\n",
    "    max_horiz = np.max([np.max(np.abs(tr.data)) for tr in st_horiz])\n",
    "    max_vert = np.max([np.max(np.abs(tr.data)) for tr in st_vert])\n",
    "    #print(r[\"Song name\"], r[\"Starttime\"], r[\"Endtime\"], max_horiz*1000, max_vert*1000, max_horiz/max_vert)\n",
    "    #if r[\"Song name\"] in [\"You Belong With Me\", \"Love Story\"]:\n",
    "    #    print(r[\"Song name\"])\n",
    "    #    st_fri_trim.plot()\n",
    "    df.loc[idx, 'max_horiz_displacement_mm'] = max_horiz * 1000\n",
    "    df.loc[idx, 'max_vert_displacement_mm'] = max_vert * 1000\n",
    "\n",
    "\n",
    "    cmap = plt.cm.plasma\n",
    "    norm = plt.Normalize(vmin=0, vmax=tr_N.times(reftime=tr_N.stats.starttime)[-1])\n",
    "    BHH = np.sqrt(tr_E.data**2 + tr_N.data**2)\n",
    "    ax = axs[idx]\n",
    "    ax.set_facecolor(\"black\")\n",
    "    ax.scatter(tr_E.data, tr_N.data, c=cmap(norm(tr.times(reftime=tr_E.stats.starttime))), \n",
    "               s=40000000*np.power(BHH, 1.5)+1, alpha=0.6, edgecolors=\"k\", linewidths=0.3)\n",
    "    maxx = np.max([np.max(np.abs(tr_E.data)), np.max(np.abs(tr_N.data))])\n",
    "    ax.set_xlim([-maxx, maxx])\n",
    "    ax.set_ylim([-maxx, maxx])\n",
    "\n",
    "\n",
    "    string = []\n",
    "    for n_word, word in enumerate(r[\"Song name\"].split()):\n",
    "        if n_word > 0 and n_word % 3 == 0:\n",
    "            string.append(word + \"\\n\")\n",
    "        else:\n",
    "            string.append(word)\n",
    "    string = [s.lstrip() for s in string]\n",
    "    string = \" \".join(string)\n",
    "    string = string.replace(\"\\n \", \"\\n\")\n",
    "\n",
    "    ax.text(0.03, 0.97, string,\n",
    "     horizontalalignment='left',\n",
    "     verticalalignment='top',\n",
    "     transform = ax.transAxes, fontsize=6, c=\"white\", wrap=True)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.savefig(\"/Users/sph1r17/Downloads/SeismoSwiftArt.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8683f6c8-b9ac-4852-84f0-bb5b1dd9c8fd",
   "metadata": {},
   "source": [
    "# 3. Compute and plot particle motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b834169-098e-4a21-bc93-f2acd7088748",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(7, 7, figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for idx, r in df.iterrows():\n",
    "    st_fri_trim = st_fri_.slice(UTCDateTime(r[\"Starttime\"]), UTCDateTime(r[\"Endtime\"]))\n",
    "    st_vert = st_fri_trim.select(component=\"Z\")\n",
    "    st_horiz = st_fri_trim.copy()\n",
    "    tr_E = st_fri_trim.select(component=\"E\")[0]\n",
    "    tr_N = st_fri_trim.select(component=\"N\")[0]\n",
    "\n",
    "\n",
    "    for tr in st_horiz:\n",
    "        if tr.stats.component==\"Z\":\n",
    "            st_horiz.remove(tr)\n",
    "    max_horiz = np.max([np.max(np.abs(tr.data)) for tr in st_horiz])\n",
    "    max_vert = np.max([np.max(np.abs(tr.data)) for tr in st_vert])\n",
    "    #print(r[\"Song name\"], r[\"Starttime\"], r[\"Endtime\"], max_horiz*1000, max_vert*1000, max_horiz/max_vert)\n",
    "    #if r[\"Song name\"] in [\"You Belong With Me\", \"Love Story\"]:\n",
    "    #    print(r[\"Song name\"])\n",
    "    #    st_fri_trim.plot()\n",
    "\n",
    "    # Compute peak ground displacements for each song\n",
    "    df.loc[idx, 'max_horiz_displacement_mm'] = max_horiz * 1000\n",
    "    df.loc[idx, 'max_vert_displacement_mm'] = max_vert * 1000\n",
    "\n",
    "\n",
    "    cmap = plt.cm.plasma\n",
    "    norm = plt.Normalize(vmin=0, vmax=tr_N.times(reftime=tr_N.stats.starttime)[-1])\n",
    "    BHH = np.sqrt(tr_E.data**2 + tr_N.data**2)\n",
    "    ax = axs[idx]\n",
    "    ax.set_facecolor(\"black\")\n",
    "    ax.scatter(tr_E.data, tr_N.data, c=cmap(norm(tr.times(reftime=tr_E.stats.starttime))), \n",
    "               s=40000000*np.power(BHH, 1.5)+1, alpha=0.6, edgecolors=\"k\", linewidths=0.3)\n",
    "    maxx = np.max([np.max(np.abs(tr_E.data)), np.max(np.abs(tr_N.data))])\n",
    "    ax.set_xlim([-maxx, maxx])\n",
    "    ax.set_ylim([-maxx, maxx])\n",
    "\n",
    "\n",
    "    string = []\n",
    "    for n_word, word in enumerate(r[\"Song name\"].split()):\n",
    "        if n_word > 0 and n_word % 3 == 0:\n",
    "            string.append(word + \"\\n\")\n",
    "        else:\n",
    "            string.append(word)\n",
    "    string = [s.lstrip() for s in string]\n",
    "    string = \" \".join(string)\n",
    "    string = string.replace(\"\\n \", \"\\n\")\n",
    "\n",
    "    ax.text(0.03, 0.97, string,\n",
    "     horizontalalignment='left',\n",
    "     verticalalignment='top',\n",
    "     transform = ax.transAxes, fontsize=6, c=\"white\", wrap=True)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.savefig(\"/Users/sph1r17/Downloads/SeismoSwiftArt.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b953a37-b955-49a2-b259-967d5da594e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "df.plot.barh(x=\"Song name\", y=\"max_vert_displacement_mm\", ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
